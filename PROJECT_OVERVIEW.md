# ğŸ“‹ Project Overview - Research Intelligence Platform

## ğŸ¯ What is This Project?

This is a **Multi-Agent AI Research Platform** that autonomously discovers, validates, synthesizes, and analyzes academic research from multiple sources. Think of it as your AI research assistant that can:

1. **Search** ArXiv, Semantic Scholar, and the web simultaneously
2. **Validate** sources for credibility and relevance
3. **Synthesize** findings into knowledge graphs
4. **Analyze** using ML (topic modeling, clustering, predictions)
5. **Generate** comprehensive research reports
6. **Monitor** emerging trends and new research

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Streamlit UI    â”‚   OR    â”‚  Command Line    â”‚          â”‚
â”‚  â”‚  (Web Browser)   â”‚         â”‚  (Terminal)      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                          â”‚ â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                           â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LANGGRAPH ORCHESTRATOR                           â”‚
â”‚  (Coordinates all agents via state machine)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚              â”‚
    â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Discoveryâ”‚  â”‚Validationâ”‚ â”‚   RAG    â”‚
â”‚ Agent   â”‚â†’ â”‚  Agent   â”‚â†’â”‚  Agent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼              â–¼              â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Synthesis â”‚  â”‚   ML   â”‚  â”‚Reporter â”‚  â”‚Monitoringâ”‚
â”‚  Agent   â”‚â†’ â”‚ Agent  â”‚â†’ â”‚  Agent  â”‚â†’ â”‚  Agent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚            â”‚             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  OUTPUTS & STORAGE    â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ Research Reports    â”‚
        â”‚ â€¢ Knowledge Graphs    â”‚
        â”‚ â€¢ Vector Database     â”‚
        â”‚ â€¢ ML Analysis         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Directory Structure Explained

```
datascienceproj/
â”‚
â”œâ”€â”€ 1_Documentation/          ğŸ“š Documentation & problem statements
â”‚   â””â”€â”€ Your project docs go here
â”‚
â”œâ”€â”€ 2_Data/                   ğŸ’¾ Raw and processed data
â”‚   â”œâ”€â”€ raw/                  Raw downloaded research data
â”‚   â””â”€â”€ processed/            Validated, cleaned sources
â”‚
â”œâ”€â”€ 3_Notebooks/              ğŸ““ Jupyter notebooks for experiments
â”‚   â””â”€â”€ Testing and analysis notebooks
â”‚
â”œâ”€â”€ 4_Src_Code/               ğŸ”§ Main source code
â”‚   â”œâ”€â”€ agents/               Individual agent modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py          Shared state definition
â”‚   â”œâ”€â”€ agentic_ai_pipeline.py  â­ MAIN PIPELINE (all agents)
â”‚   â””â”€â”€ README.md             Code documentation
â”‚
â”œâ”€â”€ 5_Pipeline/               ğŸ”„ Airflow orchestration
â”‚   â”œâ”€â”€ airflow_dag.py        Production DAG
â”‚   â””â”€â”€ README.md             Airflow setup guide
â”‚
â”œâ”€â”€ 6_Models/                 ğŸ¤– ML models & vector stores
â”‚   â””â”€â”€ vectorstore/          ChromaDB vector database
â”‚
â”œâ”€â”€ 7_Results/                ğŸ“Š Generated outputs
â”‚   â”œâ”€â”€ *.png                 Knowledge graph visualizations
â”‚   â””â”€â”€ *.txt                 Research reports
â”‚
â”œâ”€â”€ 8_Demo/                   ğŸ¬ Demo materials
â”‚   â”œâ”€â”€ screenshots/          UI screenshots
â”‚   â””â”€â”€ demo_video.mp4        (You'll record this)
â”‚
â”œâ”€â”€ 9_Deployment/             ğŸš€ Deployment files
â”‚   â”œâ”€â”€ app.py                â­ STREAMLIT WEB UI
â”‚   â””â”€â”€ README.md             Deployment guide
â”‚
â”œâ”€â”€ requirements.txt          ğŸ“¦ Python dependencies
â”œâ”€â”€ README.md                 ğŸ“– Main project documentation
â”œâ”€â”€ PROJECT_OVERVIEW.md       ğŸ“‹ This file
â”œâ”€â”€ run_streamlit.bat         â–¶ï¸  Windows launch script
â”œâ”€â”€ run_streamlit.sh          â–¶ï¸  Linux/Mac launch script
â”‚
â””â”€â”€ (Airflow files - if using Docker orchestration)
    â”œâ”€â”€ docker-compose-airflow.yml
    â”œâ”€â”€ AIRFLOW_README.md
    â””â”€â”€ setup_airflow.bat
```

## ğŸš€ How to Use

### Quick Start (3 Steps)

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set API Keys**
   Create `.env` file:
   ```env
   GROQ_API_KEY=your_key_here
   SERPAPI_KEY=your_optional_key
   ```

3. **Launch UI**
   ```bash
   # Windows
   run_streamlit.bat
   
   # Linux/Mac
   chmod +x run_streamlit.sh
   ./run_streamlit.sh
   ```

### Usage Modes

#### Mode 1: Web UI (Recommended â­)
```bash
streamlit run 9_Deployment/app.py
```
- **Best for**: Interactive research, visualizations
- **Port**: http://localhost:8501
- **Features**: Real-time progress, downloadable reports

#### Mode 2: Command Line
```bash
python 4_Src_Code/agentic_ai_pipeline.py
```
- **Best for**: Automated runs, scripting
- **Output**: Terminal output + saved files

#### Mode 3: Airflow (Production)
```bash
docker-compose -f docker-compose-airflow.yml up -d
```
- **Best for**: Scheduled runs, production deployment
- **Port**: http://localhost:8080
- **Features**: Scheduling, monitoring, alerts

## ğŸ§  How It Works (Step-by-Step)

### Step 1: User Input
- Enter research query (e.g., "Transformer models for computer vision")
- Select depth (quick/standard/deep)

### Step 2: Discovery Agent ğŸ”
- Searches ArXiv for academic papers
- Queries Semantic Scholar for peer-reviewed research
- Searches web via SERPAPI (if configured)
- Deduplicates results

### Step 3: Validation Agent âœ…
- Scores each source (0-100) based on:
  - Source type (peer-reviewed vs preprint)
  - Citation count
  - Recency
  - Content quality
- Checks relevance using LLM
- Filters out low-quality sources

### Step 4: RAG Agent ğŸ§ 
- Creates vector embeddings using HuggingFace
- Stores in ChromaDB vector database
- Enables semantic search across sources

### Step 5: Synthesis Agent ğŸ§¬
- Extracts key concepts
- Identifies consensus findings
- Detects contradictions
- Finds research gaps
- Builds knowledge graph (nodes + edges)

### Step 6: ML Agent ğŸ¤–
- **Topic Modeling**: Discovers hidden topics using LDA
- **Clustering**: Groups similar papers using K-means
- **Citation Prediction**: Predicts future impact
- **Quality Scoring**: ML-based assessment

### Step 7: Reporter Agent ğŸ“Š
- Generates executive summary
- Creates detailed research report
- Builds citation map
- Prepares visualizations

### Step 8: Monitoring Agent ğŸ“¡
- Sets up alert triggers
- Analyzes trends
- Tracks emerging topics
- Identifies key authors

### Step 9: Output ğŸ“
- **Text Report**: Comprehensive analysis (saved to `7_Results/`)
- **Knowledge Graph**: Visual PNG (saved to `7_Results/`)
- **Vector DB**: Semantic search database (`6_Models/vectorstore/`)
- **JSON Data**: Structured data for further processing

## ğŸ¨ Streamlit UI Features

### New Research Tab ğŸš€
- Enter research query
- Select depth
- Real-time progress tracking
- Agent execution visualization

### Results Tab ğŸ“Š
- Executive summary card
- Key metrics dashboard
- Interactive knowledge graph display
- Key concepts (as badges)
- Consensus findings
- Research gaps (expandable)
- ML analysis:
  - Topics discovered (LDA)
  - Paper clusters (K-means)
  - Citation predictions
- Top sources with citations
- Download buttons (TXT, JSON, PNG)

### History Tab ğŸ“š
- View past research sessions
- Access previous reports
- Browse generated graphs

## ğŸ”§ Customization

### Change LLM Model
Edit `4_Src_Code/agentic_ai_pipeline.py`:
```python
llm = ChatGroq(
    api_key=groq_api_key,
    model="llama-3.1-8b-instant",  # Change this
    temperature=0.3
)
```

### Modify UI Theme
Edit `9_Deployment/app.py`:
```python
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(120deg, #YOUR_COLOR, #YOUR_COLOR);
    }
</style>
""", unsafe_allow_html=True)
```

### Adjust Search Parameters
In `4_Src_Code/agentic_ai_pipeline.py`:
```python
# Discovery Agent
all_sources.extend(self.search_arxiv(query, max_results=8))  # Change this
```

### Add New Agent
1. Create agent class
2. Add to workflow in `create_research_workflow()`
3. Define edges (execution order)

## ğŸ“Š Output Files Explained

### Research Report (`report_*.txt`)
```
- Executive summary
- Key findings
- Notable insights
- Research gaps
- Conflicting evidence
- Conclusion
- Source citations
```

### Knowledge Graph (`kg_*.png`)
- **Blue circles**: Key concepts
- **Red circles**: Research sources
- **Lines**: Relationships/connections
- **Size**: Importance/centrality

### Vector Database (`chroma_db/`)
- Embeddings for all validated sources
- Enables semantic similarity search
- Used by RAG agent

## ğŸ› Troubleshooting

### Streamlit won't start
```bash
# Check if port is in use
streamlit run 9_Deployment/app.py --server.port 8502
```

### Import errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### API key issues
- Check `.env` file exists in project root
- Verify keys are correct (no quotes needed)
- Or enter keys in Streamlit sidebar

### No knowledge graph generated
- Check `7_Results/` folder
- Ensure matplotlib is installed
- Look for errors in console output

## ğŸ“ˆ Performance Tips

### Faster Execution
- Use "quick" depth for testing
- Reduce `max_results` in search methods
- Use smaller LLM model

### Better Results
- Use "deep" depth for comprehensive research
- Add SERPAPI key for web search
- Use larger LLM model (llama-3.1-70b-versatile)

### Save Costs
- Use cached results when re-running
- Disable web search if not needed
- Use "quick" depth as default

## ğŸ“ Learning Resources

### Understanding the Code
1. Start with `4_Src_Code/README.md`
2. Read each agent's docstrings
3. Check `ResearchState` in `agents/state.py`

### LangGraph Concepts
- **Nodes**: Individual agents (functions)
- **Edges**: Execution flow between agents
- **State**: Shared data structure (TypedDict)
- **Workflow**: State machine that orchestrates agents

### RAG Explained
- **R**etrieval: Find relevant documents
- **A**ugmented: Add to LLM context
- **G**eneration: LLM generates answer with context

## ğŸŒŸ Next Steps

1. **Try it out**: Run a simple query
2. **Explore UI**: Check all tabs and features
3. **Read reports**: Analyze generated outputs
4. **Customize**: Modify agents for your needs
5. **Deploy**: Use Streamlit Cloud or Docker
6. **Extend**: Add new agents or features

## ğŸ“ Support

If you encounter issues:
1. Check the relevant README:
   - `README.md` - Main docs
   - `4_Src_Code/README.md` - Code details
   - `9_Deployment/README.md` - UI/deployment
   - `5_Pipeline/README.md` - Airflow setup
2. Look for error messages in console
3. Check file paths and dependencies
4. Verify API keys are set correctly

## ğŸ‰ Congratulations!

You now have a powerful AI research assistant that can:
- âœ… Search multiple academic databases automatically
- âœ… Validate and score sources for quality
- âœ… Synthesize findings across papers
- âœ… Generate knowledge graphs
- âœ… Perform ML analysis
- âœ… Create comprehensive reports
- âœ… Monitor research trends

**Happy Researching! ğŸ”¬**

---

Â© 2025 | Built with LangGraph, Groq LLM, ChromaDB & Streamlit


